{"componentChunkName":"component---src-pages-index-tsx","path":"/","webpackCompilationHash":"937b644821a2433c38c2","result":{"data":{"site":{"siteMetadata":{"title":"Jeff Rafter"}},"allMarkdownRemark":{"edges":[{"node":{"excerpt":"GitHub Actions are still in beta and are changing quickly. But if you are looking to get started the possibilities are endless. This guide is mostly about pointing to documentation and exploring some fun ways to use GitHub Actions. In this post we’ll create a single repository which contains a GitHub Action - built in TypeScript - and an associated workflow. In the action we’ll respond to push events and output some logging information. Technically, you don’t need a custom script to accomplish this; you could instead build a very simple workflow which runs  commands. Using a full script will allow us to explore more capabilities of GitHub Actions. Before you read this it is important to note: starting with a template will save you a lot of time and setup. In this post, however, I am going to work through and explain all of the steps. Included in this post are some of the reasons I’ve chosen one particular setup and skipped another. When getting started with GitHub Actions it is difficult to understand how all of the pieces fit together, or why you might want to create and action for a particular task. Hopefully this post provides some helpful examples. That said, there are probably steps here that you’ve seen before, don’t care about, or just want to skip and that’s okay. In order to follow this, you’ll need a GitHub account. Additionally, you’ll need to sign up for the GitHub Actions beta. The examples will be in TypeScript. All of the code (and commits) are availble on GitHub: https://github.com/jeffrafter/example-github-action-typescript Documentation The documentation for GitHub Actions is really good (far more complete than this post) and is good to have on hand. You can learn how to build Actions, Workflows and core concepts; as well as dive deeply on using the toolkit, octokit and handling payloads. Automating your Workflow with GitHub Actions GitHub Package Toolkit Event Types & Payloads Rest API V3 octokit/rest.js Getting started First you want to create a folder for your project: We’ll be using TypeScript to build our action, which requires Node. Out of the box GitHub supports a few environments for your actions to run . There is built-in support for running actions built in JavaScript (using Node). So why did I choose to use TypeScript? It makes development a lot easier by providing compile-time checks and hints in my editor about methods and parameters (especially if you are using an editor like VSCode that has support for it). As part of our action we’ll export the TypeScript to JavaScript. Let’s setup our example to use Node. If you have multiple local projects you might run into a conflict about which Node version should be used. Node Version Manager solves this problem. To control which version of Node should be used in your project, add an  file: The file is pretty simple; just the version. I chose 10.16.3 because it matches the version that is installed in the default GitHub Action software environment. At the time you read this there may be a newer version of Node or you may chose to use an older version because your code requirements. You can check https://nodejs.org.  Ignore some things We plan to use  to keep track of our changes. As we work on our project locally, there will be a lot of files we won’t want to keep track of; we’ll want to ignore them. To do this we’ll create a new file called  . These files can be very short and specific, or they can be very long and general. We’ll use a more generic one that will work on different kinds of computers. If you are looking for an example  you can check out https://github.com/github/gitignore. For now, just copy the following: With this setup we’ll ignore  and JavaScript files in our action folders (if there was any generated locally). This is a non-standard choice but makes developing our action a little easier. By default, GitHub recommends you include the  folder as installing them per-action execution is slow (25-35 seconds). Including all of the  in your repository can lead to a lot of files and large commits which can be confusing. Additionally, if your  include platform specific dependencies which must be compiled (such as ) you will need to recompile them for the target action container anyway. Ignoring generated JavaScript in our action folders means that we have to build our TypeScript as part of our workflow. Again, this is slower and can lead to compile time errors on the server, but it saves us a few steps when developing actions.  Save your progress using version control At this point we really haven’t made anything (except a lot of configuration). Even though our website isn’t even a website yet – it still makes sense to save our work. If we make a mistake having our code saved will help us. To do this we’ll use  - a version control software that lets us create commits or versions as we go. To initialize a  repository run: By default this creates an empty git repository (none of our files have been added to it). Generally, I use GitHub Desktop; however, I’ll use the command line here. You can check the status of your changes and repository: You should see: Let’s get ready to create a commit by adding all of the files: Here the  means: “everything in the current folder”. But what are we adding it to? We are adding it to the commit stage. Let’s check the status again: You should see: We’re getting ready to add two new files to our repository. Let’s commit: This creates a commit with the message we specified. The commit acts like a save point. If we add or delete files or change something and make a mistake, we can always revert back to this point. We’ll continue to commit as we make changes.  Packages & Dependencies For almost any Node project you’ll find that you use a lot of packages – you’ll have far more code in packages in your  folder (where package code is stored) than your main project. Initialize your packages: Now you have a : Let’s simplify it a bit (you can fill out or keep fields you like here, but this is the minimum): The only scripts we need at the moment are  which will convert our TypeScript to JavaScript and  which will run our tests. While we’re working on our action we’ll need access to all of our project’s dependencies; the difference between  and  won’t matter very much. For that reason we’ll install everything as a  dependency: The  and  are the baseline for interacting with GitHub and the incoming events. When you publish an action which is meant to be used by multiple repositories and workflows, you’ll release the action with dependencies included (so they run more quickly). In that case you would use  instead of . In most other cases the code for your actions should only be used as part of your testing or development environment (not part of your production environment). We’ll want to add testing support to test our action: And TypeScript support: Finally, because we’re using TypeScript, we’ll want to add type support for development: This is a good opportunity to create another commit; check the status: You should see: We’ve added a lot of files to our folder but many of them are ignored. For example, the  folder contains tons of files (as mentioned before). We want everyone working on our project to install the same dependencies. When installing, they were automatically added to the  file. The  ensures that the dependencies of our packages are locked to specific versions. Because of this, we’ll add both of these files to : And then commit:  TypeScript We’ll also need to configure TypeScript before we can build our action. Create : By default this allows us to build all of the actions contained in our repository, adds some strict compile-time checks, and skips type checking for our dependencies. Let’s commit this file: You should see: Add it: And commit: Keep it clean Everyone has different preferences when they edit code. Some prefer tabs over spaces. Some want two spaces instead of four. Some prefer semicolons and some don’t. It shouldn’t matter right? But it does. If editors are autoformatting code based on user preferences it is important to make sure everyone has chosen the same set of defaults for that autoformatting. This makes it easy to tell what changed between versions – even when different developers (with different preferences) have made changes. For this reason we’ll setup a linter and code formatter for our code. Install eslint and prettier: Now that we have the packages we’ll need to configure them in : I won’t go into too much detail here; there are better explanations to be found. This configuration does a few things: Relies on the typescript eslint parser with the prettier plugin - I’ve found this works very well in @Code. If you were previously using  with prettier this setup should replace your old configuration. This eslint config doesn’t work perfectly for projects that contain both JavaScript and TypeScript - because of that we won’t attempt to lint JavaScript files in our project I’ve turned off the camelcase rules for properties - when writing GitHub Actions you will likely use properties from  and from the API and these will not be camelcase. The expected environment should include  and  - this will help  ignore missing declarations for things like , , , etc. If you need to ignore specific files when linting you can add them to . Because our setup doesn’t work well for JavaScript we’ll ignore all JavaScript files in : Notice that we are explicitly unignoring the  folder. This is where our source code will be kept (see next section). We have to unignore this folder explicitly because it starts with a  and is normally ignored by eslint. Add a  action to the  node in : With this in place we can run: Wait, there’s an error: We haven’t written any TypeScript to lint yet. Time to stop configuring and start writing code. Checking our  should show our changes: This makes sense; we’ve added two files and installed some new  into our packages. Let’s add everything and to the commit stage: If we check  again: Let’s commit:  Project Layout The code for GitHub Actions are generally kept in the  folder in the  folder. By default, the  folder contains metadata for the repository that can be used for automated tasks. The steps for running an action are defined in a Workflow which is usually stored in the  folder in the  folder: Repositories can contain multiple actions (or none at all); we’ll define our debug action inside a folder called . This will contain our TypeScript, generated JavaScript, tests, and the  where all of the settings for the action are kept. A repository may also have multiple workflows (or none at all); we’ll setup a workflow that runs our debug action inside .  Building the debug action Enough setup; let’s get building. Create a new file called : The code inside your action should be auto-executing. In this case we define a  method and then immediately call it right after it has been defined. In fact, you don’t even need to define a method, you could include the code for your action directly. In some cases that might be okay, but as the complexity of the action increases it would become confusing. We’ve also made our function the default export. This isn’t required but will make things easier as we move forward and test our code. There are lots of helpers built into the  package we imported. This is the simplest. Because we’re using TypeScript you may see autocomplete information in your editor:  At this point the action does nothing. Lets add some debugging: Even though this action isn’t accomplishing much, let’s write a test for it. Testing the debug action Create a new file called : We import the actions core library and the run method we just created in our debug action. In our test we create a Jest spy which allows us to verify that the  method is getting called with the correct parameters. Normally, I wouldn’t test the debug output (if it fails I don’t care too much) but this is a good foundation. In order to run this we’ll need to configure Jest. Create a new file called  in the root of your project: At this point you can run the tests. From your terminal run: You should see: It should pass. But let’s remove the debug information from the test output. Change  so that it doesn’t output the debug lines: With that change the debug output should no longer appear when we run the tests. We can run our  task to verify that our code is clean: It should succeed this time with no errors and no warnings. Let’s commit what we have. Run : Let’s add those files: Note, one of the items listed was the  folder. When we added it all of the newly added files inside of that folder were also added. Let’s check the status again: Notice that we are about to commit three files: Commit: Create the action.yml for the debug action We’ve written the code for our action and a test that tells us it is working. Unfortunately we haven’t defined how our action should be used. To do that we have to configure the action in a  file. Create : There are more configuration options available for actions but this represents the minimum amount needed to run. Specifically, it gives the action a name (which does not need to match the name of the folder) and points to the the code . Unfortunately, we don’t have a file called , we have a file called . GitHub Actions have built-in support for JavaScript and cannot run TypeScript directly. Because of this we will need to transpile our TypeScript to JavaScript before it can be run. This is done with  (the TypeScript compiler). We’ve already included a task: This will generate JavaScript files  (and ): In our setup we’ve ignored these files - they will not be included when we push our code to GitHub. This isn’t the recommended setup; GitHub suggests you include the built files for your actions to save time when running your action (and to reduce the dependencies needed by your action on the server). When developing actions it is easy to forget to build your code with each change. Because of this I’ve chosen to automatically build on execution (even though it is slower). When releasing the action it is best to include the built JavaScript.  Workflows In order to execute the  we’ve created we need to create a workflow. The  in our action defines the code to execute and the workflow defines when to execute it. Workflows should be kept in the  folder in your repository. Your repository may contain multiple workflows. Create : We’ve created a workflow that should be executed on . There are many different events that trigger worklows. By specifying  we’re saying that every time new code is pushed to our GitHub repository our workflow should be executed. In this case we’ve chosen to execute our workflow using the  environment. The steps for a workflow can point to an action that should be used or a command that should be run. Here we use both. The first step checks out our code using the  action: The  action checks out a copy of your code on the server where the workflow is running. We’ve set the fetch-depth to  indicating we only want a shallow-clone. When your action code is included in your  folder (as our  is), you must use the  action to checkout a copy of the code so that it can run. A shallow clone of the code ignores all of the history. Since our action doesn’t use any of the history this is a good speedup. The next two steps install our action dependencies and build it: Again, this is generally discouraged because it is slower and takes more resources. While developing, however it is much more simple. Finally we use our debug action: This should be enough to run our . Let’s commit: You should see: Let’s add the workflow: And commit:  Pushing to GitHub Our action and workflow are ready. All that’s left is to push to our repository on GitHub. Create a new repository. I called mine  and made it public.  Once you’ve created the repository you’ll need to click the  button make sure to setup the remote for your repository to use  instead of HTTPs:  Unfortunately you can’t push workflow changes via HTTPs as it is considered an integration. If you try you’ll see something like the following when you try to push: Setup your remote by copying the instructions on the page for : Then push: On GitHub, click on the  tab of your repository and click on the running build. When complete you should see something like:  The action ran and the build was marked as complete. But we can’t see the debug information we added. By default, GitHub will not output debug information in the action logs. To see debug output in the logs you need to add a new secret to your repository. Go to the  tab of your repository and click  on the sidebar. Then click . Set the name to  with the value  and click . Currently, there is no way to re-run an action. We’ll see the debug information when we push a new commit.  Using action input By default GitHub injects default environment variables that can be used by your action including:           (only in forks)  (only in forks) These are commonly used, but there are many instances where you want to change how an action runs based on configuration in each workflow that uses that action. Let’s add an input to our debug action that changes what the debug message says. First, define the input and default in : We’ve defined a new input called . When the action is executed the name will be will be converted to and the value will be passed in via the process environment. Environment variable names normally wouldn’t have  in them as we see in . Because of the  we need to access the values as strings. The key names in YAML syntax can vary wildly but only spaces are replaced with underscores. You could access the values directly  but using  as we have done is more future-proof. Let’s use it. Change : If we save that file and re-run our tests we’ll see a new failure: Being an amazing  is not very gratifying. The problem is that our test doesn’t know about the environment variable . Let’s set it in the test in : Setting the environment variable directly will make our test pass. After our test is complete we remove the variable to reset our state. We could do this setup and teardown with  and  callbacks: We’ve also called  which will prevent other imported modules from using a cached value. The test should still pass. What if you have a lot of inputs? It would be nice to automatically import all of the defaults. To do this we’ll need to read the  and assign all of the defaults to the environment. Install the type definitions for : And then lets expand our  and  callbacks: While this is cool, it probably adds complexity rather than reducing it. Still, it is helpful to get an idea of how the action is being executed. Our workflow can take advantage of the newly created property: We’ve added a  node to our action definition and specified the value  as our . Let’s commit and push these changes to GitHub. We should see the output this time because we turned debug output on. Check : That’s a lot of files. Add all of them: And commit: Finally let’s push to GitHub:   Action outputs Debugging output is useful but actions are much more powerful when chained together. Each action can define a set of outputs that can be used by subsequent actions. Additionally an action can set it’s status. This is especially useful for pull request workflows as the statuses can be used for automated-approval (or rejection). Suppose we want to set an output containing our message so that other steps in our workflow can use it. We can define the output in our : Here we’ve called it  and set the . In  let’s use it: We can add a test for this: We can use the output in our workflow: We’ve given our action an  node, then we refer to that  in our echo command. Let’s commit this. Run : Add the changes: And commit: And push it to GitHub: Once we’ve push this to GitHub we’ll see:  Each action can have multiple outputs.  Setting status of the action By default, if our action crashes it will fail. We can make this explicit: If the exception is handled and the program can continue we can make use of the logging functions instead:    Catching exceptions is great, but failures can happen for other reasons. For example, suppose someone chose  as the . That’s not okay: We can test this in : Get the : Add and commit in one step:  Payloads Actions are intended to respond to events: when code is pushed, when a pull request is opened or updated, when someone leaves a comment, scheduled events, etc. Every action is passed a payload. Events that trigger workflows Event Types & Payloads The easiest way to work with a payload is to try it out and log the payload to the console: Notice we added an import for the  toolkit: Then we logged the . If you push this to GitHub to run you might see: The push event documentation can be really helpful. With this information we can make our message more personal. We’ll include the name of the person pushing the code. Utilizing the information in the  node is useful but that’s only available for  actions. If you want to know who triggered the workflow for other kinds of actions you can use the  default environment variable. In this case we’ll use the value from the payload. Change : We’ll need to change our tests as well. We’ll directly set the payload in the : We could store payloads as files and use those as well, but this approach is more readable. Run : And commit: And push to GitHub: It is so encouraging! Give some love to anyone that opens an issue Writing output to the logs is fine. Setting the completion and failed status of the action is also cool. Automating your workflow using the API is the best. Actions can automatically create issues, pull request reviews, commits and more. To demonstrate, let’s create a new action. When a friendly contributor opens an issue in our repository our GitHub Action will thank them and add a reaction to their issue. We’ll add the following:  Using the API Every action that runs has access to a  environment variable that can be used to interact with the API. The token has read and write (but not admin) repository app permissions by default. Virtual Environments documentation To use the  you must configure the environment of your action when it is referenced in the workflow. Remember actions can be used by many workflows in many repositories and granting access should be protected.\nThe workflow for our thanks action will be triggered when an issue is opened. Create : Each step that makes use of the  must include: We’ll also need a new  for our thanks action. Create : Notice that we’ve specified an input with a default message. If we wanted we could specify different messages in our workflows that use this action. With the environment set we’re ready to create : Let’s break this down. Using  events to trigger our workflow allows us to respond to newly opened issues. However, every change to an issue will trigger our workflow: when an issue is opened, closed, edited, assigned, etc. Because of this we want to make sure our action is only making changes when the issue is opened: We’ll need to access the  in the payload: At this point we grab the token that was injected into the environement from our workflow: We use the token to create a new GitHub client: The client that is created is actually an octokit/rest.js API client. The  client has full access to the Rest API V3. There is great documentation available: octokit/rest.js @actions/github Rest API V3 Once you have a  client you’ll usually want to work with the current repository. There are a set of automatically included environment variables to make this easier. For example, the  environment variable contains the repository name with owner () like : At this point we’re ready to create a comment replying to the opened issue. We grab the  from the action input. Then we create the comment via the  client: Calling the API requires HTTP interactions which are not instant. Because working with the API involves asynchronous callbacks, most API calls will return a  containing a response object (with , , and ). if If you don’t care about the result, you can ignore the response and continue on. If you need to use the response, however, you’ll need to use  to let the  request complete. Here we are logging out the comment URL from the response so we need to use  to make sure the response is complete. We also want to add a reaction to the issue: Again we use  to wait for the response from the API call. Testing API interactions Whem working with the API it is important to configure your tests so they don’t actually interact with GitHub’s API. In general, you don’t want your tests to call the API directly; they might start creating real issues in your repositories or use up your rate limits. Instead you should be mocking all of the external calls from your test suite. This will also make your tests run faster. It is common to use  to mock external requests and responses. Install it along with the supporting types: There are great examples available in the  repository on mocking the octokit client and in the  README. By default, we want to disable all external calls from our test suite. To do this add the following to the top of : Now if one of our tests attempts use the API nock will prevent it and fail the test with an error like: Let’s create a new test. Create : We start off by setting up a fake payload. The real payload (when GitHub runs our action) will be much bigger and contain more information; however we’ve made our example payload in the test as small as possible to keep things focused. The test that we’ve created does nothing more than attempt to run our action. We’re not verifying any output or debug information (though we could). Instead we are validating that the API endpoints are hit with specific parameters. If these mocked API requests don’t occur (as we have specified them), the test will fail: Notice that we are also specifying the response body. This allows our action code to utilize the response exactly as it would from a real API interaction. Again, when developing your action you might use  to see what the actual output looks like before setting up your tests. Some might argue that this level of mocking for your tests is too much. We’re faking the input, faking the API endpint and faking the responses. So what is this test even doing? The approach here is one of efficiency. I’m trusting that the GitHub API works and that the way I’ve set it up won’t change. With those assumptions set in my tests, I’m free to change the code that leads up to those interactions in any way I see fit. I’ve mocked the edges, but my actions code still must do the right thing. It’s a trade-off but once you’ve established how the edges of your code work it allows much faster iteration. If we run the tests with  we see: At this point the action works. Let’s check : Let’s add all of those: And commit: And push to GitHub: When we pushed, our  still executed, but not our new . In order to trigger that we have to open a new issue. Open a new issue with any message and then watch the action execute. You should see something like:  It works! But… it doesn’t feel very personal to have a bot replying to collaborators. It would feel much better if a human were replying. Unfortunately all of the interactions with the repository are on behalf of the GitHub Actions bot because we are using the . In order to act on behalf of another user we’ll need to use a different token. o do this, we’ll generate a personal access token. To create a token, go to your token settings in GitHub (click on  in the user drop-down menu, then  in the sidebar, then click on ). Then click the  button.  Make sure you’ve checked the  box to grant repository access permissions to the token. Copy the token (note, this is just an example and this token has been revoked so you can’t use it):  Next, we’ll need to add a new secret to our repository. Open the setings for your repository and click  in the sidebar. Click  and set the name to  and paste the copied personal access token into the . Click .  Now that we’ve created a new secret containing our token we need to use it. To use it, we’ll need to modify our workflow. Right now the  node in our workflow specifies the . Let’s add an entry for the : This will inject the secret into our environment. We’ll need to modify  to use it. Currently we have: Let’s change that to: That’s it. At this point  should still pass and  should have no warnings or errors. Let’s check the : And commit: Push it to GitHub: Open a new example issue and you should see your user account reply:  Thanks Lots of folks @GitHub helped review and solve some of the issues I came across while writing this post. Special shout-outs go to @jasonetco, @mscoutermarsh, and mikekavouras. Also, special thanks to the docs team and the octokit/rest.js team who make great things.","fields":{"slug":"/working-with-github-actions/"},"frontmatter":{"date":"September 13, 2019","title":"Working with GitHub Actions","excerpt":"GitHub Actions are still in beta and are changing quickly. But if you are looking to get started the possibilities are endless."}}},{"node":{"excerpt":"The Oculus Quest is entirely immersive and a blast to play with. Of course, the moment I put it on, I immediately wanted to make my own games and got started with Unity. There are a few blog posts and videos that helped me on my way.  Getting started To develop for you Oculus you’ll not only need an Oculus account but you may want to setup an Oculus Organiztion (free). Additionally (for my purposes), you’ll need a Unity account. I’m using a personal account (also free). Mac versus Windows I’m using a MacBook Pro. Many of the tutorials and videos you’ll find assume you’re working on Windows. This can create some challenges but the biggest challenges are around the platform support for the Oculus Quest itself. Oculus doesn’t make a version of it’s Oculus Desktop app (or libraries) available on MacOS. Because of this you’ll want to start with tutorials that are specific to the Mac and adjust. Unity & initial setup I followed a couple of tutorials for getting Unity Hub and Unity installed. I recommend: How to get started with Oculus Quest and Unity on macOS How to get started with Oculus Quest development in Unity If you prefer videos:  Learn Once I had the basics working, and could load games I built in Unity on my Quest, I wanted to do more. I found a set of fantastic tutorial videos by Valem, Quentin Valembois and was hooked. As I went through the videos I took notes and (with permission) am posting those here. While watching these videos, you might notice Valem is using the ▶ button to debug. This works because he is actually developing for the Rift in the videos (notice that the controllers are upside-down). In a later video on recreating Slenderman (at 1:47) he explains how to use the ▶ button while building for the Oculus Quest. Unfortunately that won’t work on MacOS because the Oculus plugin is not supported. There are notes on how to get this working at the end of this post.  A note on the Oculus Integration asset The Oculus Integration in the Unity Asset Store solves an amazing amount of problems for you. Unfortunately,\nthe updates are not necessarily backward compatible and it makes following tutorials difficult. Most\nof the tutorials listed here were for the 1.38 version. The current 1.39 version requires a few more steps. After you download and import the kit you’ll restart Unity. You should see a new menu for Oculus:  Choose  | . Choose  |  From your project search, find the newly created  and open it in your editor.\nYou’ll want to change  to  so that\nwhen you choose  it will actually run the generated APK on your Oculus Quest. Also, you need to indicate you are using  with a  element. Here is the full file: If you’re using a  you’ll notice you don’t have hands. You’ll need to add an application id in  |  | . You can get an Application Id by creating an application for your organization on the Oculus Developer website at https://dashboard.oculus.com | . There’s a good shortcut for testing though: just enter  for the  field.  How to make a VR game in Unity - Part 1 - Setup, Hand presence, Grabbing object Setup the project Set Unknown Sources in the Oculus app (Windows only) In Unity Hub create a new 3D app Click Build Settings in the File menu Choose Android, click Switch Platform Change the Texture Compression to ASTC (not required, very slow) Open Player Settings: Set the Company and Product Name Remove  from the Graphics APIs list (Other Settings) Set the Package Name (Other Settings) Set the Minimum API Level to Android 4.4 ‘KitKat’ (Other Settings) Check VR Intergation (XR Settings) Add the Oculus Virtual Reality SDK (XR Settings) Download Oculus Integration from the Asset Store (slow) Import All from the Oculus Integration (very slow) If you leave this at the default of , nothing will happen when it attempts to deploy the player. Unity will appear to complete but your Quest will do nothing (not even install the application to Unknown Sources). Change the package name to  or a name matching what you have named your Company and Product Name. Make the scene Create a 3D plane Create a 3D cube Create a red material and apply it to cube Create a black material and apply it to plane Delete the main camera Add  to the scene and move it back away from the cube Set Tracking Origin Type to  on the  child (note: if you are using the ▶ button, this should be ) Add the  component to the  Drag the  to the  Camera Rig field Check the Dynamic Height box Note: As of 1.39 you also need to set the Target Devices of the OVR Manager (Script) to Quest  Simple grabbing Add  prefab to the  of the  Add  and  prefab to the  Make the red cube wider (more like a table) Add an empty object called Cubes and add some cubes (6 of them) Select all of the cubes and add the  script Add the  component Build and run In Build Settings click Add Open Scenes Plug in your Oculus (you may need to “Trust this computer”) On Windows you should be able to click play On Mac click Build and Run (slow first build) From the comments: Colliding with the cubes and flying into the air? “Some of you have experienced a bug where the player fly when you put your hands under you. A really simple fix is to set the body and the hand to a different layer then in Physics settings uncheck the collision between the two layer in the collision layer matrix! :) Hope this will help some of you!” https://www.youtube.com/watch?v=sKQOlqNe_WY&lc=Ugy0IV2wmiRMywTkPk94AaABAg Note: setting up layer interactions happens more in the next section.  How to make a VR game in Unity - Part 2 - Custom Hand, Distance grab Setting up custom hands Remove the  you added Add  and  to the scene Select both, drag the  of the  to the Parent Transform property of the custom hands Find the  component in , expand the Materials section and set the material to  (same as the material for ) Expand the  material, change the Inner Color to aqua, increase the Rim Power Go to Project Settings | Time and change the Fixed Timestep to   Setting up distance grab Remove the custom hands Select all of the cubes Set the Collision Detection to Continuous Dynamic Remove the OVR Grabbable Script Add the Distance Grabbable Script Add  and  prefabs to scene Set the Player field to the  Set the  to the Parent Transform Set the Grab Object in Layer field to the number corresponding to your Cubes Layer (9) Set Obstruction Layer to -1 (none) Create an Empty Game Object and call it Grab Manager and add it to the  (this is different from the video, but solves the problem where only one box can be grabbed, also this is fixed in the following videos) Add the Sphere Collider component to the Grab Manager Set Is Trigger to true Set the Radius to something larger (3.5 is good) Adding the crosshairs Click the object that you want to have a crosshair on Once selected, create an Empty Game Object called Crosshair Add the Grabbable Crosshair Script to the object Create a child Quad object called “On” Remove the mesh collider of the quad Add the  Material Move it slightly behind the cube Duplicate the child Quad and call it “Off” Change the material to  Make it smaller by lowering the scale Change the material color to gray Drag  to the Targeted Crosshair field of the Crosshair script Drag  to the Enabled Crosshair field of the Crosshair script Make a prefab from the crosshair (drag from the scene to Assets) Drag the prefab into the remaining cubes  How to make a VR game in Unity - Part 3 - VR Shooter Setup the gun In the Asset Store find the asset: “Modern Guns: Handgun” published by NOKOBOT. Smash the download button. Click Import, then Import All Open the folder in Assets, Nokobot, ModernGuns_Handgun, Prefabs, Active guns Drag  prefab into the scene Scale it down (0.3) and move it to the left of the boxes Add a  component Add the  script Set the layer to the Grabbable layer (same as Cubes) Add a new Empty 3D object to the gun called  Add a new Cube to  that aligns to the barrel  Duplicate that cube to  and align the duplicate to the grip  Remove the Mesh Renderer of both cubes Remove the Cube (Mesh Filter) of both cubes Drag each cube to the Grab Points field of the Distance Grabbable object in the gun Add the crosshair prefab to the gun Scale the crosshair down a little bit Modify the Distance Grabbable script Click on the gun, go to the Distance Grabbable object, click the gear and choose Edit Script. Everywhere we are using the  check if null and return (): Modify the Grab Manager script Click on the Grab Manager in the  Click the gear icon on the Grab Manager Script and choose Edit Script Change  to : Fix the gun position and make it snap Note the position of the gun; remember where it is (-1, 1.15, -0.23) Move the gun position to 0, 0, 0 (temporarily) Create an Empty Game Object called Hand Gun Offset Move the object to 0, 0, 0 then align it where the gun should be held  Drag the empty game object to Assets to make a prefab Replace the gun where you had it on the table Drag the Hand Gun Offset prefab to the gun Snap Offset Check Snap Position and Snap Orientation Fix the DistanceGrabber script for the left hand Click on the  Click on the gear icon in the Distance Grabber component and choose Edit Script Copy the else statement of  into  Handle shooting if grabbed Modify the  script replacing the  method with a new  method: Add a new  method to the  script (at line 50): Click on the gun object in the scene hierarchy Add a new component  as a New script Make the script: Set the Shooting Button field of the new script to  Modify some variables Click on the gun, change the Shot Power field to 1500 Double-click the  value in the Controller field of the Animator component Click on the Shooting node and set the speed to 10  How to make a VR game in Unity - Part 4 - User Interface The wrong way Right click on the Scene Hierarchy, select UI, then click Canvas Right click on the Canvas, select UI, then click Text Select the text, click on the box and select Stretch Mode  Change Left, Top, Pos Z, Right, Bottom all to 0 Change the font size to 135 Change the text to “Not VR Friendly Text” Select the Canvas, change the Render Mode to Screen Space - Camera Fixing it Select the Canvas, change the Render Mode to World Space Scale down the Canvas to 0.001, 0.001, 0.001 Reset the position to 0, 2, 1 Change the text of the Text node to “VR Friendly Text” Making a bullet display Move the Canvas component to a child of the gun Reset the position to 0, 0, 0 and then move and scale the canvas Change the text to 0 Modify the  script to track the number of bullets: Assign the Text component to the Bullet Text property Make an interactable button Create another Canvas in the scene Add a Button to the Canvas Select the Canvas, change the Render Mode to World Space Scale down the Canvas to 0.001, 0.001, 0.001 Reset the position to 0, 2, 1 Select the Button change the scale to 4, 4, 1 Select the Text node child of the Button Change the text to “More cubes!” Remove the Canvas Raycaster component from the Canvas Add the  script to the Canvas Delete the  from the scene Search your project for  and drag the prefab into the scene Drag the  game object (in UIHelpers) to Pointer field of the  component of the Canvas Set the Event Camera of the Canvas to the  of the  in the  Make the button do something Add a component to the Button game object called  (new script) Once created, click the gear icon and Edit Script: Drag the Cubes game object from the scene to the Assets in your project to create a prefab Drag the Cubes prefab to the  field of the  script on the Button In the Button object’s Button Script click the  in the On Click() section Drag the  script into the slot marked None Choose the  function Add Raycasting Select the Sphere under the object and increase the scale Select the  check the box for the Line Renderer Change the width in Postions to 50% (0.005) In the , click on the gear icon of the Laser Pointer (Script) and choose Edit Script Add  to the  private field: In the editor change the field to   How to make a VR game in Unity - Part 5 - Controller Vibration Add a gunfire sound Unless you already have a Desert Eagle sound effect here are some good choices (search for them in the Asset Store): Post Apocalypse Guns Demo by SOUND EARTH GAME AUDIO (AutoGun1p01.wav) Futuristic Gun SoundFX by MGWSOUNDDESIGN (GunShot9.wav) Fog of War Gun Sound FX Free by INTO THE VOID SOUND DESIGN (impacter.wav) Setup the Audio Source Select the gun game object and add an Audio Source component Uncheck Play on Awake Set the Spatial Blend to 3D Modify the  script to add : Haptic feedback Create an empty game object called Vibration Manager and reset the position Add a component to the object called  (new script) Edit the  script: Edit the  script and add the following line (just after the call to  in ): Custom haptic clips Edit the  script and add another version of the  method: Within the  script, replace the call to  with:  Debugging on MacOS and the ▶ button in Unity Note: the following is for Oculus Integration 1.39 To get setup: Remove the Main Camera Set the Tracking Origin Type of the  to  Click ▶ and you’ll see:  This error is occuring because the  static variable is . You could remove this line, but it will only lead to another problem down the line. Instead fix the  by changing this line (for me it is line 40) of : to: Changing this eliminates the error, but the OVR Headset Emulator script will not work. The problem is that the  is never initialized and therefore the  is never initialized. The  method (at line 893 for me) looks like: The Unity Editor on Mac does not support the  (it is an unsupported platform). That’s fine, but let’s pretend it was initialized, even though it is unsupported (changing  to ): With this, the ▶ button should work for some quicker debugging. Note: nothing is running on the Oculus when you use that button, it is all faked. As of 1.39, when you are finished playing your scene the  block will be called for  (if you have a ).\nYou’ll see an error in the console (though it really doesn’t cause a problem). To fix it change: to:  Seeing what is happening on the Oculus Quest Building programs for the Rift was easier because you could debug everything that was happening in realtime. On the Quest you can’t but you can see what is happening on the device and view logs using , the Android Debug Bridge. On a Mac, in a Terminal, run: Once that is installed, attach your Oculus via USB-C and run: This should attach a view for a single eye. If you want to see both eyes you can just use  . If you get an error about the connection you can usually run: If that doesn’t work you can do the more extreme: And then run  again. You can also connect to the Quest and see the logs. For more information on using  with the Oculus Quest you can follow the tutorial. Checking the logs All of your  files are running on the quest and you can’t really investigate what is happening\nthrough Unity. However, you check the logs from the Quest. The logs are verbose so it is sometimes\nhelpful to start by clearing them: Then check them: You can append to the log using  statements in your application. Connecting via Wi-fi First you’ll want to make sure that the device is connected via USB: Once you’ve got the device connected you can check it’s local IP address: Now setup  for the connected device and tell it to listen on port : Once you’ve done this the device is still connected to USB and your computer is communicating via\nUSB but it is also listening for  connections via Wi-Fi. Connect to it via Wi-Fi: At this point you can unplug the USB cable and you should still be able to work with the Quest via\n over Wi-Fi. For example: If you want to explicitly connect to a particular Quest you can specify the server with : To go back to using USB, plug in the cable again and connect:  More learning I’ve used other resources when learning. I’ll list some of them here: The Ultimate Guide to Game Development with Unity 2019. This course costs between $10-12 if you catch it on sale. I highly recommend it if you are just getting started. It clearly explains how to move around the Unity interface, how to move quickly, and basic concepts of scripting. Using the new Terrain Tools: Speed up your work with the new Terrain Tools Package. Using GitHub Desktop to Manage your Project and How to use GitHub with Unity (youtube).","fields":{"slug":"/oculus-quest/"},"frontmatter":{"date":"July 25, 2019","title":"Developing for the Oculus Quest","excerpt":"Everyone wants to talk about consumer VR. I just want to make some games."}}},{"node":{"excerpt":"Creating a static website involves an almost infinite set of choices. Among these is\nGatsby – a static site framework based on , ,  and\nmany other modern approaches. Gatsby is, in many ways, the JavaScript successor to\nJekyll. I’ve upgraded several sites to Gatsby (including this one) finding\na way to integrate TypeScript as part of the journey. Before you read this it is important to point out: you should start with a template. In this post I\nam going to work through all of the steps and try to explain them along the way. Included\nin this post are some of the reasons behind why I’ve chosen one particular plugin or skipped\nanother. Often – especially when you choose a default Gatsby starter – it is difficult to understand\nhow all of the pieces fit together, or how you might build your own starter template. Hopefully\nthis post provides some helpful examples. Also: the Gatsby documentation is extremely good. There is a\nfantastic tutorial, quick start and some recipes. I’ve relied on those and a host of other blogs when working on this\npost. In order to follow this, you’ll need access to a terminal (or console) and you’ll need Node, Node Version Manager, and git installed. All of the code (and commits) are availble on GitHub: https://github.com/example-gatsby-typescript-blog/example-gatsby-typescript-blog.github.io Getting started First you want to create a folder for your project: We’ll be using Gatsby which is a toolkit that is written in TypeScript and requires Node. If you have multiple local projects you might run into a conflict about which Node version should be used. Node Version Manager solves this problem. To control which version of Node should be used in your project, add an  file: The file is pretty simple; just the version. At the time you read this there may be a newer version of Node. You can check https://nodejs.org.  Ignore some things We plan to use  to keep track of our changes. As we work on our project locally, there will be a lot of files we won’t want to keep track of; we’ll want to ignore them. To do this we’ll create a new file called  . These files can be very short and specific, or they can be very long and general. We’ll use a more generic one that will work on different kinds of computers. If you are looking for an example  you can check out https://github.com/github/gitignore. For now, just copy the following: Configure your editor This section is completely optional. This is here mostly so I can copy and paste the configuration for myself. 🎡 If there are several people working on your project, the chances are high that they use different editors for their code. At the very least their settings might not be consistent. You can provide hints to their editors. This can be done by including a generic  file (based on the format from https://editorconfig.org): Depending on the editor this may or may not be used. Not to worry, we’ll add  later which will ensure that the code is consistent. You might be using VSCode. In that case you can add some additional configuration. To do that you can create a  folder with the settings for your project. Create the folder: And in that folder make   Keeping things clean People have different preferences when they edit code. Some prefer tabs over spaces. Some want\ntwo spaces instead of four. Some prefer semicolons and some don’t. It shouldn’t matter right?\nActually it does. If editors are autoformatting code based on user preferences, it is important\nto make sure everyone has chosen the same set of defaults. This makes it easy to tell what changed\nbetween versions – even when different developers (with different preferences) have made changes. Prettier &  Prettier works to autoformat your code based on a shared configuration. To do this, create\na  file: You might have different preferences in your project. That’s fine, so long as all of the developers\non your website agree.  Because we’ll be using TypeScript, we’ll want to use TSlint. “Linting” is very similar to using\nprettier and in fact the two toolkits work together. To configure , create a new file called : Because we’ll be using it with prettier we will also want to create a  file:  Save your progress using version control At this point we really haven’t made anything (except a lot of configuration). Even though our website isn’t even a website yet – it still makes sense to save our work. If we make a mistake having our code saved will help us. To do this we’ll use  - a version control software that lets us create commits or versions as we go. To initialize a  repository run: By default this creates an empty git repository (none of our files have been added to it). Generally, I use GitHub Desktop; however, I’ll use the command line here. You can check the status of your changes and repository: You should see: Let’s get ready to create a commit by adding all of the files: Here the  means: “everything in the current folder”. But what are we adding it to? We are adding it to the commit stage. Let’s check the status again: You should see: We’re getting ready to add four new files to our repository. Let’s commit: This creates a commit with the message we specified. The commit acts like a save point. If we add or delete files or change something and make a mistake, we can always revert back to this point. We’ll continue to commit as we make changes.  Packages & Dependencies For almost any Node project you’ll find that you use a lot of packages – you’ll have far more code in packages in your  folder (where package code is stored) than your main project. Initialize your packages: Now you have a : Let’s simplify it a bit: We’ll start off by installing packages for Gatsby. There are a lot of options and this list contains\nmy own opinions: This matches my setup for Gatsby; because I tend to write about code I want to support syntax-highlighting. Prism highlights code blocks in multiple languages: And better support for styled components: Additionally, we’ll want to customize some parts so we’ll install React: And TypeScript support: Finally, because we’re using TypeScript, we’ll want to add type support for development: Our website still doesn’t work, but this is a good opportunity to create another commit; check the\nstatus: You should see: We’ve added a lot of files to our folder but many of them are ignored. For example, the\n folder contains tons of files (as mentioned before), but it isn’t necessary to keep\nthose in our version control () because they can easily be reinstalled on any machine. We want\neveryone working on our project to install the same dependencies. When installing, they were\nautomatically added to the  file. The  ensures that the\ndependencies of our packages are locked to specific versions. Because of this, we’ll add both of\nthese files to : And then commit: Setting up Gatsby At this point we have a solid foundation but not much to show for it. Let’s setup Gatsby so that\nwe can see some output. Gatsby is made up of a collection of packages, many of which are optional\nbased on your particular use case. Which packages you choose to use is configured in three files:  - general configuration and plugins  - build time and development generation and resolvers  - client side code bundled to run in a user’s browser  Configuration -  The configuration is broken down into two main sections:  and a list of ,\nsome of which have custom options. Here is the whole  file: Let’s break down each part.  The  section is entirely custom. You can put whatever you want in here and later use\nit in your pages (using GraphQL, which we’ll cover later). The fields that I’ve specified are\ncommonly used by different Gatsby sites and are often supported in different plugins and themes.  There are a list of plugins. Like the  section you have a lot of choices.  The first two plugins are actually all the same: . This allows us to\nuse files in our folder to generate our website. In this case we’ve split the site content into\ntwo different folders:   This isn’t a requirement, it just helps us with organization later: You’ll see these sources used when we dig into the  configuration.  Gatsby has a class of plugins called “transformers”. These plugins take the content (from the folders\nspecified above) and transform them to be viewable as HTML (and other formats). Remark is a\ntransformer based on  which converts Markdown content to HTML. Markdown is a text format\nthat is intended to be quicker and easier to type – while giving you a consistent output. The output can be more complex, and because of that there are a set of plugins that extend Remarkable listed as well: The extensions:  - autosizes the images so they fit better with the rest of the content  - syntax highlighting for code blocks  - allows iframes to resize correctly  - adds a link target (and ) to each header in your posts  - copies externally linked files to your project on build  - converts quotes and apostropes to smart-quotes and smart-apostrophes  and  The sharp image plugin and transformer enhance and size your images. These work together with\nbut can also be used on other images throughout your site.  Do you have a fancy ? Do you want it to work in every browser and mobile device and also\nwork as a home-screen icon and Desktop cover photo? Generating all of those and creating a manifest\nto refer to them is cumbersome… unless you use :  When you deploy your website you may have a custom domain name like . However you\nmight have additional ways to get to your site such as  or\n. When Google’s search engine sees the same content at three different sites\nit thinks something is fishy. Setting a “canonical URL” tells Google (and others), “Hey, if you\nfind this content via different URLs, just ignore that and use the canonical URL.”  If you want to use Google Analytics you can add it via the plugin and all of the default scripts\nwill be injected automatically:  Though we’ve included some plugins that inject content into the  of each webpage, you may\nwant to include custom content, such as OpenGraph tags or Twitter cards. For this, you’ll need . React generally focuses on the  of webpages, but  focuses on\nthe .  Gatbsy has good support for styled components (or CSS-in-js). Many Gatsby users use Emotion. I tend to prefer the patterns in https://www.styled-components.com/ which this plugin enables.  We’ll be developing in TypeScript. This plugin adds support (including typings) to help while\ndeveloping.  Build time and development server -  When developing your website or when building, Gatsby (running on Node) relies on the setup in\n. This is where all of the pages for the website are transformed and\ngenerated. As with other parts of Gatsby there are lots of options here. For our setup, we need to\nexport two functions:   Create a file called : Let’s break it down piece by piece. We’ll start off by requiring a couple of packages we’ll need: Next we’ll write the  function. The function starts with a GraphQL query. GraphQL is\nan API that accesses a datastore— in this case Gatsby itself. The plugins that we’ve installed\ninto Gatsby provide content; specifically the  grabs all of the files\nin the specified locations and transforms them using . This provides a\nresource containing the rendered markdown. We execute the query (asyncronously), selecting the specific fields we want. Each markdown file\nwill have frontmatter: a formatted set of fields before the Markdown content starts. For example: Each one of these fields is available as items in the  connection in GraphQL. However,\nif you try to access an item via GraphQL and it is not listed in the  of every page\nyou’ll get an error. For this reason we only grab the  and the  and require that\nthese are set in the  of each post. Once the GraphQL query completes we handle the result. If there is an error we immediately throw it.\nThis only happens at development or build time so throwing the error should give us immediately\nuseful feedback: In the next part of the function we setup our templates. We have two kinds of pages: Post pages Tag pages We’ll construct these templates a little later. Next we’ll use the data we fetched (now in the GraphQL result) and generate each page using the\n method that was passed to us: Notice that we are checking for a  and  page and passing them into the \nfield when we create the page. Each of the context fields will be converted to  we can\nuse in our  templates. The  and  allow us to build a carousel in the\nfooter of our pages. At a minimum our website should be able to display the posts we write. For my website I wanted to\nbe able to add  to posts to easily group them together. In the  I can supply a\nlist of tags: In our generator we’ll loop through all of the posts and grab all of the tags. Once we have\nthem all we’ll make them unique (using the  trick) so that there are no duplicates. For\neach tag we’ll create a new page using our  template: With this we can create all of the pages. There is one small problem: in our GraphQL query we\nselected the  field: This field doesn’t exist by default – we’ll need to create it. We can do this by adding an \nfunction to our  file: Whenever a  is created this function will be called. If it is a  node we’ll\ncreate a new field called  that we generate based on the filename.  Client side -  In general, you want to keep the client side JavaScript and stylesheets as minimal as possible.\nThis helps your pages load fast and keeps users (and Lighthouse checks) happy. Some of the plugins\nwe’ve chosen will generate client-side JavaScript automatically. In fact, for our setup we only need\nto add one requirement. Create : This will inject the CSS for our syntax highlighting into the downloadable payload.  Save your progress With our configuration complete we should create another commit: You should see: Add those files: And commit them: Building the site structure: layout, pages, templates, styles and components Now that we have the configuration of the site we’ll need to setup the structure. This\nincludes things like the header and footer on each page and how the pages look. We’ll\ncreate the  page the  and more. Here’s the file structure: Notice that most of these files are in the  folder.  Styles For some, the design and presentation of a website is the most important aspect. There are a lot of\noptions when theming a Gatsby site (a giant inlined CSS stylesheet isn’t necessarily ideal). For\nexample, we could split our CSS into modules, rely only on locally styled components, or fully\nsupport Gatsby themes. For now we will start with something very basic: a simple CSS reset\nand an inline stylesheet.Create the file : The important pieces here are  and the generic reset. The styles that are in\nthe  function are based on Edward Tufte’s\nstyles. This provides a very minimalist theme to build on.  Layout Now that we have our basic styles we can move on to the layout. A website’s layout includes\nthe header of the page, maybe the site navigation and the site’s footer that appears on every page.\nIt is the thing that makes each page feel consistent. Create : First, we create a couple of custom styled components:   Styled components allow you to inject custom CSS at the component level and in this case are only\nused in this file. We can name them anything we want but it is common to prefix the name\nwith Styled. We then declare the  interface. Declaring interfaces and types is what gives TypeScript its\npower. Here we are saying that the component can accept an optional  property. You’ll notice\nthat in the component itself we access the  prop. We get that for free (it is\ninherited) from . The  itself, is a simple React component. We use the styled components we created to build\na small site-navigation with links to our main pages, we have a main content area and a footer.\nThe only other component is the global style declaration: We inject this inside our layout (not in the ) so that changes to the style will trigger a\nre-render when using hot-module-reloading.  Head Like the  component, the  component will be used on every page. We’ll use it to setup\nkeywords,  tags (like OpenGraph tags and Twitter cards) and more. Create the\nfile : The first thing we do is declare a  type. When the  component is built\nwe execute a . This is a GraphQL query that will execute and fetch results from\nGatsby similarly to the  query we saw earlier: In this query we are accessing  which we setup earlier in .\nBecause we are using TypeScript we want to declare a type for the expected result and each of\nits fields: The type and the query are very similar. If you add a field to one of them you have to add it\nto the other. The  prop of  is executed and the results are passed to the render\nfunction declared in the  prop. We’ll use the default configuration for most props but allow some overrides to be passed in. For\nexample each page may choose to have a different  so we allow that to be passed in.\nThe header is rendered using a  element from .  Bio Creating a  component isn’t required. I’ve created one mostly as a placeholder in case I want\nto add more components throughout the site. Create : This component is very similar to our  component. It uses a  declaration to\nexecute a GraphQL query to fetch some values from our  config. Then it renders the results.\nWe could expand this component if we wanted to, possibly allowing for an  prop to be passed\nin the event that we had multiple authors.  Pages With the basic structure like  and  in place we can start building out individual pages.\nWhen the user attempts to navigate to a particular page Gatsby will first look for a corresponding\npage created via  in . If it doesn’t find the page there it will\nnext look for a page in . For example, if a user goes to , Gatsby will try to find . For the\nroot page of the site (also known as the ) we can create a file called .\nEach page in the  folder should export a default  component. Additionally,\nit can export a  constant. The  constant is a GraphQL query that will be\nexecuted prior to rendering the component. The results from the query will be passed into the\ncomponent as a  called .  Page The  is the home page of our website. Create the file : Let’s break this down. We start of by importing the components we created earlier: Then we declare an interface for the  we expect to receive when this component is rendered.\nAs we saw earlier, pages in Gatsby are passed the result of a GraphQL query. The type of  is . We haven’t declared that type yet; it’s declared lower in\n. The  component itself is fairly straightforward. We render all of the content in the page\ninside of a  component (imported above) so that the page looks consistent with the rest\nof the site. We’ve included the  and  for the same reason. The rest of the content\nis a list of articles constructed by looping through the : Notice that we link to each page using the  object. Gatsby is really great at rendering\ncontent on the client side and the  component helps handle that routing where possible. Lastly, we construct the query and the corresponding interface: Again, we could have selected any of the fields we wanted (we aren’t required to select them all).  Page The  page follows the same pattern of the . Create a file\ncalled : We haven’t added any real content to this page; it is here more as a placeholder. If you want to\nadd pages (such as a terms of service or privacy page), this file can serve as a basic example.  Page The  page of website is what the user should see when they attempt to go to a page that\ndoesn’t exist. This page is special because it isn’t rendered based on the name. Create a\nfile called :  Page When we generated all of the pages in  we created a page for each  used in\nthe frontmatter of our posts. Let’s add a page that lists all of the tags available on our site\nto make it easy to find those pages. Create a file called :  Templates We’ve created all of the pages and completed the configuration but we aren’t quite done. You’ll\nremember that when we generated the pages in  we referred to the  and \ntemplate files: We haven’t created those templates yet. Let’s do that now:  Template The  template is used when rendering each post for our blog. Create a file\ncalled : This page is very similar to the  and  pages. We export a default component and\nexport a  object that Gatsby will execute before rendering. In addition to passing\nthe  results from the GraphQL query, this template will also recieve a  object. The  object is actually constructed in the  function in .\nIn our case we’ve passed a  and  field (optional) so that we generate a carousel\nat the bottom of each post. Another interesting part of this template is the ominously named . We saw this earlier as well. What’s it doing here? When the  plugin converts our\nMarkdown it generates HTML. Normally, if we inserted the HTML directly in our template it would\nall be escaped (for example  would become ). Not escaping HTML content is considered\ndangerous as it could introduce security vulnerabilities. In this case we know that the content\nwe are injecting was already properly escaped (by the  plugin) and we know we can\nassign it directly. The prop  is named as such to prevent you using it\non accident.  Template The  template is extremely similar to the  template. Create a file\ncalled :  Static content Static assets like images, PDF documents, videos and embedded fonts will be used throughout a\nsite. We’ve only referred to one static asset in our site so far: . We linked\nto this in the manifest in . If you want to use images in your static folder elsewhere in the site you can import them directly: And then refer to returned URL: In some cases you don’t need to import the files you put in the static folder but can refer to them\ndirectly and Gatsby will automatically expand the path. For more information, see the\nstatic asset documentation.  Save your progress We’ve setup the entire structure of our Gatsby site. Really, we could have committed each of the\nfiles as we added them instead of creating a giant commit. Let’s commit again: You should see: It just shows the two folders we added to the root. Add those folders: Let’s check the status again: Now you should see: We’ve added everything recursively and all of the files we’ve created are staged for the next commit.\nLet’s commit them: Writing posts Writing content is the most important part of your blog and where you will spend most of your\ntime. When writing a post you’ll create a markdown file in  and store any images\nin . Let’s start by making the folders: Next, create a post by creating a file : Copy this Furby image and save it as :   Save your progress That’s it, we have the first post and static content: You should see: Add the  folder (and the files it contains): And commit them: Developing Now that we have content, everything should work. To get started let’s run the development server: This will prepare the package and compile all of the pages, transforming the markdown and preparing\nand executing the GraphQL: At this point you should be able to open your website in your browser: http://localhost:8000/:  The server utilizes Hot-module-reloading (HMR) so that, as you make changes, your webpage will be\nimmediately updated in the browser. This is true for themes, structure changs and content. For some changes you do need to restart the server. Generally the changes that require\na restart are related to configuration changes, for example in  or\n or if you add a new package to your . Deploying The power of Gatsby is that it can be served statically – you don’t need a server at all. There are\nlots of options for deploying. I’ve used the following: Netlify Now.sh AWS S3 GitHub Pages Since we have been keeping track of our changes in , using GitHub Pages is a natural fit (and\nfree forever). The Gatsby docs have an\nextensive set of tutorials on how to prepare and deploy your site: https://www.gatsbyjs.org/docs/deploying-and-hosting/ For me I used the  plugin and followed this tutorial: https://www.gatsbyjs.org/docs/how-gatsby-works-with-github-pages/. All of the code (and commits) are availble on GitHub: https://github.com/example-gatsby-typescript-blog/example-gatsby-typescript-blog.github.io","fields":{"slug":"/gatsby-with-typescript/"},"frontmatter":{"date":"May 25, 2019","title":"Building a Static Gatsby-based Website with TypeScript","excerpt":"Creating a static website involves an almost infinite set of choices. I've upgraded several sites to Gatsby (including this one) finding a way to integrate TypeScript as part of the journey. Gatsby leverages React, JSX, CSS-in-JS, GraphQL and many other modern approaches to building sites."}}}]}},"pageContext":{"isCreatedByStatefulCreatePages":true}}}