{"componentChunkName":"component---src-templates-tag-tsx","path":"/tags/typescript/","webpackCompilationHash":"937b644821a2433c38c2","result":{"data":{"site":{"siteMetadata":{"title":"Jeff Rafter"}},"allMarkdownRemark":{"totalCount":4,"edges":[{"node":{"excerpt":"Create a repository on github If you don‚Äôt already have an account on GitHub, create one. For me, my username is\njeffrafter. You can sign up for a free account and still host your\nblog. Note: by default, your username will be part of the URL for your blog. We can change\nthat later. Next, create a new repository and name the repository . For me, I‚Äôve\nnamed mine .  Build and push Once you‚Äôve created the repository you need to add it as an  to your local copy: Again, using GitHub Desktop can simplify pushing code as it manages\nyour login.  Pull requests and branches  Custom domains","fields":{"slug":"/deploying-gatsby-to-github-pages/"},"frontmatter":{"date":"2019-06-01T00:01:00","title":"Deploying Gatsby to GitHub Pages","excerpt":null}}},{"node":{"excerpt":"Our plan is to build a website using Next.js.\nNext.js is built on top of Express. Out of the box, it supports server side rendering, hot module\nreloading, React and more. We‚Äôll add TypeScript, Styled Components, Sessions, Authentication,\nsome basic security and more. Gatsby is client side framework for building static sites. Static sites\nare great for brochure websites, portfolios and blogs. If you are building a site which needs\nserver-side processing (e.g., sites that require authentication or server-to-server interaction such\nas payment processing) then Next.js handles both\nthe client and server side. It‚Äôs important to remember that there are countless ways to accomplish a task within the Node\necosystem. This has a positive side and a negative side. This post represents one set of choices\nI made when I wrote this. Given how quickly things move, if I started over I might not make the\nsame choices and that is okay. In order to follow this, you‚Äôll need access to a terminal (or console) and you‚Äôll need Node, Node Version Manager, and git installed. Getting started First you want to create a folder for your project: We‚Äôll be using Next.js which is a toolkit that is written in TypeScript (a typed variant of JavaScript) and requires Node. If you have multiple local projects you might run into a conflict about which Node version should be used. Node Version Manager solves this problem. To control which version of Node should be used in your project, add an  file: The file is pretty simple; just the version. At the time you read this there may be a newer version of Node. You can check https://nodejs.org.  Ignore some things We plan to use  to keep track of our changes. As we work on our project locally, there will be a lot of files we won‚Äôt want to keep track of; we‚Äôll want to ignore them. To do this we‚Äôll create a new file called  . These files can be very short and specific, or they can be very long and general. We‚Äôll use a more generic one that will work on different kinds of computers. If you are looking for an example  you can check out https://github.com/github/gitignore. For now, just copy the following:  nodemon.json   Optional If you are using VSCode, it is useful to make sure all of the developers have a consistent experience. To do that you can keep a  folder with the default settings: Create the folder: And make    You might not be using VSCode. In that case you might want to opt for the more generic  file (based on the format from https://editorconfig.org):   Because we want to use TypeScript, we‚Äôll need to run the code through Babel on build to create compatible JavaScript. Create a  file:   If you aren‚Äôt using eslint then you are likely using prettier. It is pretty safe to choose one or the other. If you choose prettier add a  file:   In general, eslint will be more powerful than prettier (though often overkill) ‚Äî offering lots of plugins and rules. If you use eslint, add an : Additionally if you‚Äôll want to ignore certain files for performance reasons, add a .   From gatsby: From a next project (server/tsconfig.js:    Configure next with  From the example (): From gist-playground  Testing with  .env\n.env.test","fields":{"slug":"/next-with-typescript/"},"frontmatter":{"date":"2019-04-23T00:01:00","title":"Next.js with TypeScript","excerpt":null}}},{"node":{"excerpt":"Creating a static website involves an almost infinite set of choices. Among these is\nGatsby ‚Äì a static site framework based on , ,  and\nmany other modern approaches. Gatsby is, in many ways, the JavaScript successor to\nJekyll. I‚Äôve upgraded several sites to Gatsby (including this one) finding\na way to integrate TypeScript as part of the journey. Before you read this it is important to point out: you should start with a template. In this post I\nam going to work through all of the steps and try to explain them along the way. Included\nin this post are some of the reasons behind why I‚Äôve chosen one particular plugin or skipped\nanother. Often ‚Äì especially when you choose a default Gatsby starter ‚Äì it is difficult to understand\nhow all of the pieces fit together, or how you might build your own starter template. Hopefully\nthis post provides some helpful examples. Also: the Gatsby documentation is extremely good. There is a\nfantastic tutorial, quick start and some recipes. I‚Äôve relied on those and a host of other blogs when working on this\npost. In order to follow this, you‚Äôll need access to a terminal (or console) and you‚Äôll need Node, Node Version Manager, and git installed. All of the code (and commits) are availble on GitHub: https://github.com/example-gatsby-typescript-blog/example-gatsby-typescript-blog.github.io Getting started First you want to create a folder for your project: We‚Äôll be using Gatsby which is a toolkit that is written in TypeScript and requires Node. If you have multiple local projects you might run into a conflict about which Node version should be used. Node Version Manager solves this problem. To control which version of Node should be used in your project, add an  file: The file is pretty simple; just the version. At the time you read this there may be a newer version of Node. You can check https://nodejs.org.  Ignore some things We plan to use  to keep track of our changes. As we work on our project locally, there will be a lot of files we won‚Äôt want to keep track of; we‚Äôll want to ignore them. To do this we‚Äôll create a new file called  . These files can be very short and specific, or they can be very long and general. We‚Äôll use a more generic one that will work on different kinds of computers. If you are looking for an example  you can check out https://github.com/github/gitignore. For now, just copy the following: Configure your editor This section is completely optional. This is here mostly so I can copy and paste the configuration for myself. üé° If there are several people working on your project, the chances are high that they use different editors for their code. At the very least their settings might not be consistent. You can provide hints to their editors. This can be done by including a generic  file (based on the format from https://editorconfig.org): Depending on the editor this may or may not be used. Not to worry, we‚Äôll add  later which will ensure that the code is consistent. You might be using VSCode. In that case you can add some additional configuration. To do that you can create a  folder with the settings for your project. Create the folder: And in that folder make   Keeping things clean People have different preferences when they edit code. Some prefer tabs over spaces. Some want\ntwo spaces instead of four. Some prefer semicolons and some don‚Äôt. It shouldn‚Äôt matter right?\nActually it does. If editors are autoformatting code based on user preferences, it is important\nto make sure everyone has chosen the same set of defaults. This makes it easy to tell what changed\nbetween versions ‚Äì even when different developers (with different preferences) have made changes. Prettier &  Prettier works to autoformat your code based on a shared configuration. To do this, create\na  file: You might have different preferences in your project. That‚Äôs fine, so long as all of the developers\non your website agree.  Because we‚Äôll be using TypeScript, we‚Äôll want to use TSlint. ‚ÄúLinting‚Äù is very similar to using\nprettier and in fact the two toolkits work together. To configure , create a new file called : Because we‚Äôll be using it with prettier we will also want to create a  file:  Save your progress using version control At this point we really haven‚Äôt made anything (except a lot of configuration). Even though our website isn‚Äôt even a website yet ‚Äì it still makes sense to save our work. If we make a mistake having our code saved will help us. To do this we‚Äôll use  - a version control software that lets us create commits or versions as we go. To initialize a  repository run: By default this creates an empty git repository (none of our files have been added to it). Generally, I use GitHub Desktop; however, I‚Äôll use the command line here. You can check the status of your changes and repository: You should see: Let‚Äôs get ready to create a commit by adding all of the files: Here the  means: ‚Äúeverything in the current folder‚Äù. But what are we adding it to? We are adding it to the commit stage. Let‚Äôs check the status again: You should see: We‚Äôre getting ready to add four new files to our repository. Let‚Äôs commit: This creates a commit with the message we specified. The commit acts like a save point. If we add or delete files or change something and make a mistake, we can always revert back to this point. We‚Äôll continue to commit as we make changes.  Packages & Dependencies For almost any Node project you‚Äôll find that you use a lot of packages ‚Äì you‚Äôll have far more code in packages in your  folder (where package code is stored) than your main project. Initialize your packages: Now you have a : Let‚Äôs simplify it a bit: We‚Äôll start off by installing packages for Gatsby. There are a lot of options and this list contains\nmy own opinions: This matches my setup for Gatsby; because I tend to write about code I want to support syntax-highlighting. Prism highlights code blocks in multiple languages: And better support for styled components: Additionally, we‚Äôll want to customize some parts so we‚Äôll install React: And TypeScript support: Finally, because we‚Äôre using TypeScript, we‚Äôll want to add type support for development: Our website still doesn‚Äôt work, but this is a good opportunity to create another commit; check the\nstatus: You should see: We‚Äôve added a lot of files to our folder but many of them are ignored. For example, the\n folder contains tons of files (as mentioned before), but it isn‚Äôt necessary to keep\nthose in our version control () because they can easily be reinstalled on any machine. We want\neveryone working on our project to install the same dependencies. When installing, they were\nautomatically added to the  file. The  ensures that the\ndependencies of our packages are locked to specific versions. Because of this, we‚Äôll add both of\nthese files to : And then commit: Setting up Gatsby At this point we have a solid foundation but not much to show for it. Let‚Äôs setup Gatsby so that\nwe can see some output. Gatsby is made up of a collection of packages, many of which are optional\nbased on your particular use case. Which packages you choose to use is configured in three files:  - general configuration and plugins  - build time and development generation and resolvers  - client side code bundled to run in a user‚Äôs browser  Configuration -  The configuration is broken down into two main sections:  and a list of ,\nsome of which have custom options. Here is the whole  file: Let‚Äôs break down each part.  The  section is entirely custom. You can put whatever you want in here and later use\nit in your pages (using GraphQL, which we‚Äôll cover later). The fields that I‚Äôve specified are\ncommonly used by different Gatsby sites and are often supported in different plugins and themes.  There are a list of plugins. Like the  section you have a lot of choices.  The first two plugins are actually all the same: . This allows us to\nuse files in our folder to generate our website. In this case we‚Äôve split the site content into\ntwo different folders:   This isn‚Äôt a requirement, it just helps us with organization later: You‚Äôll see these sources used when we dig into the  configuration.  Gatsby has a class of plugins called ‚Äútransformers‚Äù. These plugins take the content (from the folders\nspecified above) and transform them to be viewable as HTML (and other formats). Remark is a\ntransformer based on  which converts Markdown content to HTML. Markdown is a text format\nthat is intended to be quicker and easier to type ‚Äì while giving you a consistent output. The output can be more complex, and because of that there are a set of plugins that extend Remarkable listed as well: The extensions:  - autosizes the images so they fit better with the rest of the content  - syntax highlighting for code blocks  - allows iframes to resize correctly  - adds a link target (and ) to each header in your posts  - copies externally linked files to your project on build  - converts quotes and apostropes to smart-quotes and smart-apostrophes  and  The sharp image plugin and transformer enhance and size your images. These work together with\nbut can also be used on other images throughout your site.  Do you have a fancy ? Do you want it to work in every browser and mobile device and also\nwork as a home-screen icon and Desktop cover photo? Generating all of those and creating a manifest\nto refer to them is cumbersome‚Ä¶ unless you use :  When you deploy your website you may have a custom domain name like . However you\nmight have additional ways to get to your site such as  or\n. When Google‚Äôs search engine sees the same content at three different sites\nit thinks something is fishy. Setting a ‚Äúcanonical URL‚Äù tells Google (and others), ‚ÄúHey, if you\nfind this content via different URLs, just ignore that and use the canonical URL.‚Äù  If you want to use Google Analytics you can add it via the plugin and all of the default scripts\nwill be injected automatically:  Though we‚Äôve included some plugins that inject content into the  of each webpage, you may\nwant to include custom content, such as OpenGraph tags or Twitter cards. For this, you‚Äôll need . React generally focuses on the  of webpages, but  focuses on\nthe .  Gatbsy has good support for styled components (or CSS-in-js). Many Gatsby users use Emotion. I tend to prefer the patterns in https://www.styled-components.com/ which this plugin enables.  We‚Äôll be developing in TypeScript. This plugin adds support (including typings) to help while\ndeveloping.  Build time and development server -  When developing your website or when building, Gatsby (running on Node) relies on the setup in\n. This is where all of the pages for the website are transformed and\ngenerated. As with other parts of Gatsby there are lots of options here. For our setup, we need to\nexport two functions:   Create a file called : Let‚Äôs break it down piece by piece. We‚Äôll start off by requiring a couple of packages we‚Äôll need: Next we‚Äôll write the  function. The function starts with a GraphQL query. GraphQL is\nan API that accesses a datastore‚Äî in this case Gatsby itself. The plugins that we‚Äôve installed\ninto Gatsby provide content; specifically the  grabs all of the files\nin the specified locations and transforms them using . This provides a\nresource containing the rendered markdown. We execute the query (asyncronously), selecting the specific fields we want. Each markdown file\nwill have frontmatter: a formatted set of fields before the Markdown content starts. For example: Each one of these fields is available as items in the  connection in GraphQL. However,\nif you try to access an item via GraphQL and it is not listed in the  of every page\nyou‚Äôll get an error. For this reason we only grab the  and the  and require that\nthese are set in the  of each post. Once the GraphQL query completes we handle the result. If there is an error we immediately throw it.\nThis only happens at development or build time so throwing the error should give us immediately\nuseful feedback: In the next part of the function we setup our templates. We have two kinds of pages: Post pages Tag pages We‚Äôll construct these templates a little later. Next we‚Äôll use the data we fetched (now in the GraphQL result) and generate each page using the\n method that was passed to us: Notice that we are checking for a  and  page and passing them into the \nfield when we create the page. Each of the context fields will be converted to  we can\nuse in our  templates. The  and  allow us to build a carousel in the\nfooter of our pages. At a minimum our website should be able to display the posts we write. For my website I wanted to\nbe able to add  to posts to easily group them together. In the  I can supply a\nlist of tags: In our generator we‚Äôll loop through all of the posts and grab all of the tags. Once we have\nthem all we‚Äôll make them unique (using the  trick) so that there are no duplicates. For\neach tag we‚Äôll create a new page using our  template: With this we can create all of the pages. There is one small problem: in our GraphQL query we\nselected the  field: This field doesn‚Äôt exist by default ‚Äì we‚Äôll need to create it. We can do this by adding an \nfunction to our  file: Whenever a  is created this function will be called. If it is a  node we‚Äôll\ncreate a new field called  that we generate based on the filename.  Client side -  In general, you want to keep the client side JavaScript and stylesheets as minimal as possible.\nThis helps your pages load fast and keeps users (and Lighthouse checks) happy. Some of the plugins\nwe‚Äôve chosen will generate client-side JavaScript automatically. In fact, for our setup we only need\nto add one requirement. Create : This will inject the CSS for our syntax highlighting into the downloadable payload.  Save your progress With our configuration complete we should create another commit: You should see: Add those files: And commit them: Building the site structure: layout, pages, templates, styles and components Now that we have the configuration of the site we‚Äôll need to setup the structure. This\nincludes things like the header and footer on each page and how the pages look. We‚Äôll\ncreate the  page the  and more. Here‚Äôs the file structure: Notice that most of these files are in the  folder.  Styles For some, the design and presentation of a website is the most important aspect. There are a lot of\noptions when theming a Gatsby site (a giant inlined CSS stylesheet isn‚Äôt necessarily ideal). For\nexample, we could split our CSS into modules, rely only on locally styled components, or fully\nsupport Gatsby themes. For now we will start with something very basic: a simple CSS reset\nand an inline stylesheet.Create the file : The important pieces here are  and the generic reset. The styles that are in\nthe  function are based on Edward Tufte‚Äôs\nstyles. This provides a very minimalist theme to build on.  Layout Now that we have our basic styles we can move on to the layout. A website‚Äôs layout includes\nthe header of the page, maybe the site navigation and the site‚Äôs footer that appears on every page.\nIt is the thing that makes each page feel consistent. Create : First, we create a couple of custom styled components:   Styled components allow you to inject custom CSS at the component level and in this case are only\nused in this file. We can name them anything we want but it is common to prefix the name\nwith Styled. We then declare the  interface. Declaring interfaces and types is what gives TypeScript its\npower. Here we are saying that the component can accept an optional  property. You‚Äôll notice\nthat in the component itself we access the  prop. We get that for free (it is\ninherited) from . The  itself, is a simple React component. We use the styled components we created to build\na small site-navigation with links to our main pages, we have a main content area and a footer.\nThe only other component is the global style declaration: We inject this inside our layout (not in the ) so that changes to the style will trigger a\nre-render when using hot-module-reloading.  Head Like the  component, the  component will be used on every page. We‚Äôll use it to setup\nkeywords,  tags (like OpenGraph tags and Twitter cards) and more. Create the\nfile : The first thing we do is declare a  type. When the  component is built\nwe execute a . This is a GraphQL query that will execute and fetch results from\nGatsby similarly to the  query we saw earlier: In this query we are accessing  which we setup earlier in .\nBecause we are using TypeScript we want to declare a type for the expected result and each of\nits fields: The type and the query are very similar. If you add a field to one of them you have to add it\nto the other. The  prop of  is executed and the results are passed to the render\nfunction declared in the  prop. We‚Äôll use the default configuration for most props but allow some overrides to be passed in. For\nexample each page may choose to have a different  so we allow that to be passed in.\nThe header is rendered using a  element from .  Bio Creating a  component isn‚Äôt required. I‚Äôve created one mostly as a placeholder in case I want\nto add more components throughout the site. Create : This component is very similar to our  component. It uses a  declaration to\nexecute a GraphQL query to fetch some values from our  config. Then it renders the results.\nWe could expand this component if we wanted to, possibly allowing for an  prop to be passed\nin the event that we had multiple authors.  Pages With the basic structure like  and  in place we can start building out individual pages.\nWhen the user attempts to navigate to a particular page Gatsby will first look for a corresponding\npage created via  in . If it doesn‚Äôt find the page there it will\nnext look for a page in . For example, if a user goes to , Gatsby will try to find . For the\nroot page of the site (also known as the ) we can create a file called .\nEach page in the  folder should export a default  component. Additionally,\nit can export a  constant. The  constant is a GraphQL query that will be\nexecuted prior to rendering the component. The results from the query will be passed into the\ncomponent as a  called .  Page The  is the home page of our website. Create the file : Let‚Äôs break this down. We start of by importing the components we created earlier: Then we declare an interface for the  we expect to receive when this component is rendered.\nAs we saw earlier, pages in Gatsby are passed the result of a GraphQL query. The type of  is . We haven‚Äôt declared that type yet; it‚Äôs declared lower in\n. The  component itself is fairly straightforward. We render all of the content in the page\ninside of a  component (imported above) so that the page looks consistent with the rest\nof the site. We‚Äôve included the  and  for the same reason. The rest of the content\nis a list of articles constructed by looping through the : Notice that we link to each page using the  object. Gatsby is really great at rendering\ncontent on the client side and the  component helps handle that routing where possible. Lastly, we construct the query and the corresponding interface: Again, we could have selected any of the fields we wanted (we aren‚Äôt required to select them all).  Page The  page follows the same pattern of the . Create a file\ncalled : We haven‚Äôt added any real content to this page; it is here more as a placeholder. If you want to\nadd pages (such as a terms of service or privacy page), this file can serve as a basic example.  Page The  page of website is what the user should see when they attempt to go to a page that\ndoesn‚Äôt exist. This page is special because it isn‚Äôt rendered based on the name. Create a\nfile called :  Page When we generated all of the pages in  we created a page for each  used in\nthe frontmatter of our posts. Let‚Äôs add a page that lists all of the tags available on our site\nto make it easy to find those pages. Create a file called :  Templates We‚Äôve created all of the pages and completed the configuration but we aren‚Äôt quite done. You‚Äôll\nremember that when we generated the pages in  we referred to the  and \ntemplate files: We haven‚Äôt created those templates yet. Let‚Äôs do that now:  Template The  template is used when rendering each post for our blog. Create a file\ncalled : This page is very similar to the  and  pages. We export a default component and\nexport a  object that Gatsby will execute before rendering. In addition to passing\nthe  results from the GraphQL query, this template will also recieve a  object. The  object is actually constructed in the  function in .\nIn our case we‚Äôve passed a  and  field (optional) so that we generate a carousel\nat the bottom of each post. Another interesting part of this template is the ominously named . We saw this earlier as well. What‚Äôs it doing here? When the  plugin converts our\nMarkdown it generates HTML. Normally, if we inserted the HTML directly in our template it would\nall be escaped (for example  would become ). Not escaping HTML content is considered\ndangerous as it could introduce security vulnerabilities. In this case we know that the content\nwe are injecting was already properly escaped (by the  plugin) and we know we can\nassign it directly. The prop  is named as such to prevent you using it\non accident.  Template The  template is extremely similar to the  template. Create a file\ncalled :  Static content Static assets like images, PDF documents, videos and embedded fonts will be used throughout a\nsite. We‚Äôve only referred to one static asset in our site so far: . We linked\nto this in the manifest in . If you want to use images in your static folder elsewhere in the site you can import them directly: And then refer to returned URL: In some cases you don‚Äôt need to import the files you put in the static folder but can refer to them\ndirectly and Gatsby will automatically expand the path. For more information, see the\nstatic asset documentation.  Save your progress We‚Äôve setup the entire structure of our Gatsby site. Really, we could have committed each of the\nfiles as we added them instead of creating a giant commit. Let‚Äôs commit again: You should see: It just shows the two folders we added to the root. Add those folders: Let‚Äôs check the status again: Now you should see: We‚Äôve added everything recursively and all of the files we‚Äôve created are staged for the next commit.\nLet‚Äôs commit them: Writing posts Writing content is the most important part of your blog and where you will spend most of your\ntime. When writing a post you‚Äôll create a markdown file in  and store any images\nin . Let‚Äôs start by making the folders: Next, create a post by creating a file : Copy this Furby image and save it as :   Save your progress That‚Äôs it, we have the first post and static content: You should see: Add the  folder (and the files it contains): And commit them: Developing Now that we have content, everything should work. To get started let‚Äôs run the development server: This will prepare the package and compile all of the pages, transforming the markdown and preparing\nand executing the GraphQL: At this point you should be able to open your website in your browser: http://localhost:8000/:  The server utilizes Hot-module-reloading (HMR) so that, as you make changes, your webpage will be\nimmediately updated in the browser. This is true for themes, structure changs and content. For some changes you do need to restart the server. Generally the changes that require\na restart are related to configuration changes, for example in  or\n or if you add a new package to your . Deploying The power of Gatsby is that it can be served statically ‚Äì you don‚Äôt need a server at all. There are\nlots of options for deploying. I‚Äôve used the following: Netlify Now.sh AWS S3 GitHub Pages Since we have been keeping track of our changes in , using GitHub Pages is a natural fit (and\nfree forever). The Gatsby docs have an\nextensive set of tutorials on how to prepare and deploy your site: https://www.gatsbyjs.org/docs/deploying-and-hosting/ For me I used the  plugin and followed this tutorial: https://www.gatsbyjs.org/docs/how-gatsby-works-with-github-pages/. All of the code (and commits) are availble on GitHub: https://github.com/example-gatsby-typescript-blog/example-gatsby-typescript-blog.github.io","fields":{"slug":"/gatsby-with-typescript/"},"frontmatter":{"date":"2019-05-25T00:01:00","title":"Building a Static Gatsby-based Website with TypeScript","excerpt":"Creating a static website involves an almost infinite set of choices. I've upgraded several sites to Gatsby (including this one) finding a way to integrate TypeScript as part of the journey. Gatsby leverages React, JSX, CSS-in-JS, GraphQL and many other modern approaches to building sites."}}},{"node":{"excerpt":"GitHub Actions are still in beta and are changing quickly. But if you are looking to get started the possibilities are endless. This guide is mostly about pointing to documentation and exploring some fun ways to use GitHub Actions. In this post we‚Äôll create a repository which contains a GitHub Action - built in TypeScript - and an associated workflow. In the action we‚Äôll respond to push events and output some logging information. Technically, you don‚Äôt need a custom script to accomplish this; you could instead build a very simple workflow which runs  commands. Using a full script will allow us to explore more capabilities of GitHub Actions. We‚Äôll also create an action that automatically responds to, and reacts to, issue comments. Before you read this it is important to note: starting with a template will save you a lot of time and setup. In this post, however, I am going to work through and explain all of the steps. Included in this post are some of the reasons I‚Äôve chosen one particular setup and skipped another. When getting started with GitHub Actions it is difficult to understand how all of the pieces fit together, or why you might want to create and action for a particular task. Hopefully this post provides some helpful examples. That said, there are probably steps here that you‚Äôve seen before, don‚Äôt care about, or just want to skip and that‚Äôs okay. In order to follow this, you‚Äôll need a GitHub account. Additionally, you‚Äôll need to sign up for the GitHub Actions beta. The examples will be in TypeScript. All of the code (and commits) are availble on GitHub: https://github.com/jeffrafter/example-github-action-typescript Documentation The documentation for GitHub Actions is really good (far more complete than this post) and is good to have on hand. You can learn how to build Actions, Workflows and core concepts; as well as dive deeply on using the toolkit, octokit and handling payloads. Automating your Workflow with GitHub Actions GitHub Package Toolkit Event Types & Payloads Rest API V3 octokit/rest.js Getting started First you want to create a folder for your project: We‚Äôll be using TypeScript to build our action, which requires Node. Out of the box GitHub supports a few environments for your actions to run . There is built-in support for running actions built in JavaScript (using Node). So why did I choose to use TypeScript? It makes development a lot easier by providing compile-time checks and hints in my editor about methods and parameters (especially if you are using an editor like VSCode that has support for it). As part of our action we‚Äôll export the TypeScript to JavaScript. Let‚Äôs setup our example to use Node. If you have multiple local projects you might run into a conflict about which Node version should be used. Node Version Manager solves this problem. To control which version of Node should be used in your project, add an  file: The file is pretty simple; just the version. I chose 10.16.3 because it matches the version that is installed in the default GitHub Action software environment. At the time you read this there may be a newer version of Node or you may chose to use an older version because your code requirements. You can check https://nodejs.org.  Ignore some things We plan to use  to keep track of our changes. As we work on our project locally, there will be a lot of files we won‚Äôt want to keep track of; we‚Äôll want to ignore them. To do this we‚Äôll create a new file called  . These files can be very short and specific, or they can be very long and general. We‚Äôll use a more generic one that will work on different kinds of computers. If you are looking for an example  you can check out https://github.com/github/gitignore. For now, just copy the following: With this setup we‚Äôll ignore  and JavaScript files in our action folders (if there was any generated locally). This is a non-standard choice but makes developing our action a little easier. By default, GitHub recommends you include the  folder as installing them per-action execution is slow (25-35 seconds). Including all of the  in your repository can lead to a lot of files and large commits which can be confusing. Additionally, if your  include platform specific dependencies which must be compiled (such as ) you will need to recompile them for the target action container anyway. Ignoring generated JavaScript in our action folders means that we have to build our TypeScript as part of our workflow. Again, this is slower and can lead to compile time errors on the server, but it saves us a few steps when developing actions.  Save your progress using version control At this point we really haven‚Äôt made anything (except a lot of configuration). Even though our website isn‚Äôt even a website yet ‚Äì it still makes sense to save our work. If we make a mistake having our code saved will help us. To do this we‚Äôll use  - a version control software that lets us create commits or versions as we go. To initialize a  repository run: By default this creates an empty git repository (none of our files have been added to it). Generally, I use GitHub Desktop; however, I‚Äôll use the command line here. You can check the status of your changes and repository: You should see: Let‚Äôs get ready to create a commit by adding all of the files: Here the  means: ‚Äúeverything in the current folder‚Äù. But what are we adding it to? We are adding it to the commit stage. Let‚Äôs check the status again: You should see: We‚Äôre getting ready to add two new files to our repository. Let‚Äôs commit: This creates a commit with the message we specified. The commit acts like a save point. If we add or delete files or change something and make a mistake, we can always revert back to this point. We‚Äôll continue to commit as we make changes.  Packages & Dependencies For almost any Node project you‚Äôll find that you use a lot of packages ‚Äì you‚Äôll have far more code in packages in your  folder (where package code is stored) than your main project. Initialize your packages: Now you have a : Let‚Äôs simplify it a bit (you can fill out or keep fields you like here, but this is the minimum): The only scripts we need at the moment are  which will convert our TypeScript to JavaScript and  which will run our tests. While we‚Äôre working on our action we‚Äôll need access to all of our project‚Äôs dependencies; the difference between  and  won‚Äôt matter very much. For that reason we‚Äôll install everything as a  dependency: The  and  are the baseline for interacting with GitHub and the incoming events. When you publish an action which is meant to be used by multiple repositories and workflows, you‚Äôll release the action with dependencies included (so they run more quickly). In that case you would use  instead of . In most other cases the code for your actions should only be used as part of your testing or development environment (not part of your production environment). We‚Äôll want to add testing support to test our action: And TypeScript support: Finally, because we‚Äôre using TypeScript, we‚Äôll want to add type support for development: This is a good opportunity to create another commit; check the status: You should see: We‚Äôve added a lot of files to our folder but many of them are ignored. For example, the  folder contains tons of files (as mentioned before). We want everyone working on our project to install the same dependencies. When installing, they were automatically added to the  file. The  ensures that the dependencies of our packages are locked to specific versions. Because of this, we‚Äôll add both of these files to : And then commit:  TypeScript We‚Äôll also need to configure TypeScript before we can build our action. Create : By default this allows us to build all of the actions contained in our repository, adds some strict compile-time checks, and skips type checking for our dependencies. Let‚Äôs commit this file: You should see: Add it: And commit: Keep it clean Everyone has different preferences when they edit code. Some prefer tabs over spaces. Some want two spaces instead of four. Some prefer semicolons and some don‚Äôt. It shouldn‚Äôt matter right? But it does. If editors are autoformatting code based on user preferences it is important to make sure everyone has chosen the same set of defaults for that autoformatting. This makes it easy to tell what changed between versions ‚Äì even when different developers (with different preferences) have made changes. For this reason we‚Äôll setup a linter and code formatter for our code. Install eslint and prettier: Now that we have the packages we‚Äôll need to configure them in : I won‚Äôt go into too much detail here; there are better explanations to be found. This configuration does a few things: Relies on the typescript eslint parser with the prettier plugin - I‚Äôve found this works very well in @Code. If you were previously using  with prettier this setup should replace your old configuration. This eslint config doesn‚Äôt work perfectly for projects that contain both JavaScript and TypeScript - because of that we won‚Äôt attempt to lint JavaScript files in our project I‚Äôve turned off the camelcase rules for properties - when writing GitHub Actions you will likely use properties from  and from the API and these will not be camelcase. The expected environment should include  and  - this will help  ignore missing declarations for things like , , , etc. If you need to ignore specific files when linting you can add them to . Because our setup doesn‚Äôt work well for JavaScript we‚Äôll ignore all JavaScript files in : Notice that we are explicitly unignoring the  folder. This is where our source code will be kept (see next section). We have to unignore this folder explicitly because it starts with a  and is normally ignored by eslint. Add a  action to the  node in : With this in place we can run: Wait, there‚Äôs an error: We haven‚Äôt written any TypeScript to lint yet. Time to stop configuring and start writing code. Checking our  should show our changes: This makes sense; we‚Äôve added two files and installed some new  into our packages. Let‚Äôs add everything and to the commit stage: If we check  again: Let‚Äôs commit:  Project Layout The code for GitHub Actions are generally kept in the  folder in the  folder. By default, the  folder contains metadata for the repository that can be used for automated tasks. The steps for running an action are defined in a Workflow which is usually stored in the  folder in the  folder: Repositories can contain multiple actions (or none at all); we‚Äôll define our debug action inside a folder called . This will contain our TypeScript, generated JavaScript, tests, and the  where all of the settings for the action are kept. A repository may also have multiple workflows (or none at all); we‚Äôll setup a workflow that runs our debug action inside .  Building the debug action Enough setup; let‚Äôs get building. Create a new file called : The code inside your action should be auto-executing. In this case we define a  method and then immediately call it right after it has been defined. In fact, you don‚Äôt even need to define a method, you could include the code for your action directly. In some cases that might be okay, but as the complexity of the action increases it would become confusing. We‚Äôve also made our function the default export. This isn‚Äôt required but will make things easier as we move forward and test our code. There are lots of helpers built into the  package we imported. This is the simplest. Because we‚Äôre using TypeScript you may see autocomplete information in your editor:  At this point the action does nothing. Lets add some debugging: Even though this action isn‚Äôt accomplishing much, let‚Äôs write a test for it. Testing the debug action Create a new file called : We import the actions core library and the run method we just created in our debug action. In our test we create a Jest spy which allows us to verify that the  method is getting called with the correct parameters. Normally, I wouldn‚Äôt test the debug output (if it fails I don‚Äôt care too much) but this is a good foundation. In order to run this we‚Äôll need to configure Jest. Create a new file called  in the root of your project: At this point you can run the tests. From your terminal run: You should see: It should pass. But let‚Äôs remove the debug information from the test output. Change  so that it doesn‚Äôt output the debug lines: With that change the debug output should no longer appear when we run the tests. We can run our  task to verify that our code is clean: It should succeed this time with no errors and no warnings. Let‚Äôs commit what we have. Run : Let‚Äôs add those files: Note, one of the items listed was the  folder. When we added it all of the newly added files inside of that folder were also added. Let‚Äôs check the status again: Notice that we are about to commit three files: Commit: Create the action.yml for the debug action We‚Äôve written the code for our action and a test that tells us it is working. Unfortunately we haven‚Äôt defined how our action should be used. To do that we have to configure the action in a  file. Create : There are more configuration options available for actions but this represents the minimum amount needed to run. Specifically, it gives the action a name (which does not need to match the name of the folder) and points to the the code . Unfortunately, we don‚Äôt have a file called , we have a file called . GitHub Actions have built-in support for JavaScript and cannot run TypeScript directly. Because of this we will need to transpile our TypeScript to JavaScript before it can be run. This is done with  (the TypeScript compiler). We‚Äôve already included a task: This will generate JavaScript files  (and ): In our setup we‚Äôve ignored these files - they will not be included when we push our code to GitHub. This isn‚Äôt the recommended setup; GitHub suggests you include the built files for your actions to save time when running your action (and to reduce the dependencies needed by your action on the server). When developing actions it is easy to forget to build your code with each change. Because of this I‚Äôve chosen to automatically build on execution (even though it is slower). When releasing the action it is best to include the built JavaScript.  Workflows In order to execute the  we‚Äôve created we need to create a workflow. The  in our action defines the code to execute and the workflow defines when to execute it. Workflows should be kept in the  folder in your repository. Your repository may contain multiple workflows. Create : We‚Äôve created a workflow that should be executed on . There are many different events that trigger worklows. By specifying  we‚Äôre saying that every time new code is pushed to our GitHub repository our workflow should be executed. In this case we‚Äôve chosen to execute our workflow using the  environment. The steps for a workflow can point to an action that should be used or a command that should be run. Here we use both. The first step checks out our code using the  action: The  action checks out a copy of your code on the server where the workflow is running. We‚Äôve set the fetch-depth to  indicating we only want a shallow-clone. When your action code is included in your  folder (as our  is), you must use the  action to checkout a copy of the code so that it can run. A shallow clone of the code ignores all of the history. Since our action doesn‚Äôt use any of the history this is a good speedup. The next two steps install our action dependencies and build it: Again, this is generally discouraged because it is slower and takes more resources. While developing, however it is much more simple. Finally we use our debug action: This should be enough to run our . Let‚Äôs commit: You should see: Let‚Äôs add the workflow: And commit:  Pushing to GitHub Our action and workflow are ready. All that‚Äôs left is to push to our repository on GitHub. Create a new repository. I called mine  and made it public.  Once you‚Äôve created the repository you‚Äôll need to click the  button make sure to setup the remote for your repository to use  instead of HTTPs:  Unfortunately you can‚Äôt push workflow changes via HTTPs as it is considered an integration. If you try you‚Äôll see something like the following when you try to push: Setup your remote by copying the instructions on the page for : Then push: On GitHub, click on the  tab of your repository and click on the running build. When complete you should see something like:  The action ran and the build was marked as complete. But we can‚Äôt see the debug information we added. By default, GitHub will not output debug information in the action logs. To see debug output in the logs you need to add a new secret to your repository. Go to the  tab of your repository and click  on the sidebar. Then click . Set the name to  with the value  and click . Currently, there is no way to re-run an action. We‚Äôll see the debug information when we push a new commit.  Using action input By default GitHub injects default environment variables that can be used by your action including:           (only in forks)  (only in forks) These are commonly used, but there are many instances where you want to change how an action runs based on configuration in each workflow that uses that action. Let‚Äôs add an input to our debug action that changes what the debug message says. First, define the input and default in : We‚Äôve defined a new input called . When the action is executed the name will be will be converted to and the value will be passed in via the process environment. Environment variable names normally wouldn‚Äôt have  in them as we see in . Because of the  we need to access the values as strings. The key names in YAML syntax can vary wildly but only spaces are replaced with underscores. You could access the values directly  but using  as we have done is more future-proof. Let‚Äôs use it. Change : If we save that file and re-run our tests we‚Äôll see a new failure: Being an amazing  is not very gratifying. The problem is that our test doesn‚Äôt know about the environment variable . Let‚Äôs set it in the test in : Setting the environment variable directly will make our test pass. After our test is complete we remove the variable to reset our state. We could do this setup and teardown with  and  callbacks: We‚Äôve also called  which will prevent other imported modules from using a cached value. The test should still pass. What if you have a lot of inputs? It would be nice to automatically import all of the defaults. To do this we‚Äôll need to read the  and assign all of the defaults to the environment. Install the type definitions for : And then lets expand our  and  callbacks: While this is cool, it probably adds complexity rather than reducing it. Still, it is helpful to get an idea of how the action is being executed. Our workflow can take advantage of the newly created property: We‚Äôve added a  node to our action definition and specified the value  as our . Let‚Äôs commit and push these changes to GitHub. We should see the output this time because we turned debug output on. Check : That‚Äôs a lot of files. Add all of them: And commit: Finally let‚Äôs push to GitHub:   Action outputs Debugging output is useful but actions are much more powerful when chained together. Each action can define a set of outputs that can be used by subsequent actions. Additionally an action can set it‚Äôs status. This is especially useful for pull request workflows as the statuses can be used for automated-approval (or rejection). Suppose we want to set an output containing our message so that other steps in our workflow can use it. We can define the output in our : Here we‚Äôve called it  and set the . In  let‚Äôs use it: We can add a test for this: We can use the output in our workflow: We‚Äôve given our action an  node, then we refer to that  in our echo command. Let‚Äôs commit this. Run : Add the changes: And commit: And push it to GitHub: Once we‚Äôve push this to GitHub we‚Äôll see:  Each action can have multiple outputs.  Setting status of the action By default, if our action crashes it will fail. We can make this explicit: If the exception is handled and the program can continue we can make use of the logging functions instead:    Catching exceptions is great, but failures can happen for other reasons. For example, suppose someone chose  as the . That‚Äôs not okay: We can test this in : Get the : Add and commit in one step:  Payloads Actions are intended to respond to events: when code is pushed, when a pull request is opened or updated, when someone leaves a comment, scheduled events, etc. Every action is passed a payload. Events that trigger workflows Event Types & Payloads The easiest way to work with a payload is to try it out and log the payload to the console: Notice we added an import for the  toolkit: Then we logged the . If you push this to GitHub to run you might see: The push event documentation can be really helpful. With this information we can make our message more personal. We‚Äôll include the name of the person pushing the code. Utilizing the information in the  node is useful but that‚Äôs only available for  actions. If you want to know who triggered the workflow for other kinds of actions you can use the  default environment variable. In this case we‚Äôll use the value from the payload. Change : We‚Äôll need to change our tests as well. We‚Äôll directly set the payload in the : We could store payloads as files and use those as well, but this approach is more readable. Run : And commit: And push to GitHub: It is so encouraging! Give some love to anyone that opens an issue Writing output to the logs is fine. Setting the completion and failed status of the action is also cool. Automating your workflow using the API is the best. Actions can automatically create issues, pull request reviews, commits and more. To demonstrate, let‚Äôs create a new action. When a friendly contributor opens an issue in our repository our GitHub Action will thank them and add a reaction to their issue. We‚Äôll add the following:  Using the API Every action that runs has access to a  environment variable that can be used to interact with the API. The token has read and write (but not admin) repository app permissions by default. Virtual Environments documentation To use the  you must configure the environment of your action when it is referenced in the workflow. Remember actions can be used by many workflows in many repositories and granting access should be protected.\nThe workflow for our thanks action will be triggered when an issue is opened. Create : Each step that makes use of the  must include: We‚Äôll also need a new  for our thanks action. Create : Notice that we‚Äôve specified an input with a default message. If we wanted we could specify different messages in our workflows that use this action. With the environment set we‚Äôre ready to create : Let‚Äôs break this down. Using  events to trigger our workflow allows us to respond to newly opened issues. However, every change to an issue will trigger our workflow: when an issue is opened, closed, edited, assigned, etc. Because of this we want to make sure our action is only making changes when the issue is opened: We‚Äôll need to access the  in the payload: At this point we grab the token that was injected into the environement from our workflow: We use the token to create a new GitHub client: The client that is created is actually an octokit/rest.js API client. The  client has full access to the Rest API V3. There is great documentation available: octokit/rest.js @actions/github Rest API V3 Once you have a  client you‚Äôll usually want to work with the current repository. There are a set of automatically included environment variables to make this easier. For example, the  environment variable contains the repository name with owner () like : At this point we‚Äôre ready to create a comment replying to the opened issue. We grab the  from the action input. Then we create the comment via the  client: Calling the API requires HTTP interactions which are not instant. Because working with the API involves asynchronous callbacks, most API calls will return a  containing a response object (with , , and ). if If you don‚Äôt care about the result, you can ignore the response and continue on. If you need to use the response, however, you‚Äôll need to use  to let the  request complete. Here we are logging out the comment URL from the response so we need to use  to make sure the response is complete. We also want to add a reaction to the issue: Again we use  to wait for the response from the API call. Testing API interactions Whem working with the API it is important to configure your tests so they don‚Äôt actually interact with GitHub‚Äôs API. In general, you don‚Äôt want your tests to call the API directly; they might start creating real issues in your repositories or use up your rate limits. Instead you should be mocking all of the external calls from your test suite. This will also make your tests run faster. It is common to use  to mock external requests and responses. Install it along with the supporting types: There are great examples available in the  repository on mocking the octokit client and in the  README. By default, we want to disable all external calls from our test suite. To do this add the following to the top of : Now if one of our tests attempts use the API nock will prevent it and fail the test with an error like: Let‚Äôs create a new test. Create : We start off by setting up a fake payload. The real payload (when GitHub runs our action) will be much bigger and contain more information; however we‚Äôve made our example payload in the test as small as possible to keep things focused. The test that we‚Äôve created does nothing more than attempt to run our action. We‚Äôre not verifying any output or debug information (though we could). Instead we are validating that the API endpoints are hit with specific parameters. If these mocked API requests don‚Äôt occur (as we have specified them), the test will fail: Notice that we are also specifying the response body. This allows our action code to utilize the response exactly as it would from a real API interaction. Again, when developing your action you might use  to see what the actual output looks like before setting up your tests. Some might argue that this level of mocking for your tests is too much. We‚Äôre faking the input, faking the API endpint and faking the responses. So what is this test even doing? The approach here is one of efficiency. I‚Äôm trusting that the GitHub API works and that the way I‚Äôve set it up won‚Äôt change. With those assumptions set in my tests, I‚Äôm free to change the code that leads up to those interactions in any way I see fit. I‚Äôve mocked the edges, but my actions code still must do the right thing. It‚Äôs a trade-off but once you‚Äôve established how the edges of your code work it allows much faster iteration. If we run the tests with  we see: At this point the action works. Let‚Äôs check : Let‚Äôs add all of those: And commit: And push to GitHub: When we pushed, our  still executed, but not our new . In order to trigger that we have to open a new issue. Open a new issue with any message and then watch the action execute. You should see something like:  It works! But‚Ä¶ it doesn‚Äôt feel very personal to have a bot replying to collaborators. It would feel much better if a human were replying. Unfortunately all of the interactions with the repository are on behalf of the GitHub Actions bot because we are using the . In order to act on behalf of another user we‚Äôll need to use a different token. o do this, we‚Äôll generate a personal access token. To create a token, go to your token settings in GitHub (click on  in the user drop-down menu, then  in the sidebar, then click on ). Then click the  button.  Make sure you‚Äôve checked the  box to grant repository access permissions to the token. Copy the token (note, this is just an example and this token has been revoked so you can‚Äôt use it):  Next, we‚Äôll need to add a new secret to our repository. Open the setings for your repository and click  in the sidebar. Click  and set the name to  and paste the copied personal access token into the . Click .  Now that we‚Äôve created a new secret containing our token we need to use it. To use it, we‚Äôll need to modify our workflow. Right now the  node in our workflow specifies the . Let‚Äôs add an entry for the : This will inject the secret into our environment. We‚Äôll need to modify  to use it. Currently we have: Let‚Äôs change that to: That‚Äôs it. At this point  should still pass and  should have no warnings or errors. Let‚Äôs check the : And commit: Push it to GitHub: Open a new example issue and you should see your user account reply:  Thanks Lots of folks @GitHub helped review and solve some of the issues I came across while writing this post. Special shout-outs go to @jasonetco, @mscoutermarsh, and mikekavouras. Also, special thanks to the docs team and the octokit/rest.js team who make great things.","fields":{"slug":"/working-with-github-actions/"},"frontmatter":{"date":"2019-09-13T00:01:00","title":"Working with GitHub Actions","excerpt":"GitHub Actions are still in beta and are changing quickly. But if you are looking to get started the possibilities are endless."}}}]}},"pageContext":{"isCreatedByStatefulCreatePages":false,"tag":"typescript"}}}